<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">


    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Comfortaa:wght@300;400;600&display=swap" rel="stylesheet">
    <title> Digital Portfolio </title>
    <link rel="stylesheet" href="../../CS-II/apa.css" media="screen" />
</head>


<div class="header">
    <button type="button" onclick="window.location.href = '../../index.html';">About Me</button>

</div>

<body>

    <div class="main">
        <h5>Algorithm Awareness & The Spread of Conspiracy Theories</h5> <br />
        <h2>The Basics of Recommendation Algorithms</h2>

        <p>Recommendation algorithms work by analyzing a user's behavior on a platform. This includes actions like
            liking, sharing, searching, and the amount of time spent on particular content. By studying these actions,
            the algorithm builds a profile of the user's interests and preferences.
            <br /> <br />
            Once the algorithm has a profile, it suggests content that aligns with the user's interests. For instance,
            if a user frequently interacts with football content, the algorithm will recommend more NFL-related posts,
            videos, and articles.

        </p> <br />

        <h2>The Feedback Loop</h2>

        <p>The more a user interacts with certain types of content, the more the algorithm "learns" about their
            preferences. This leads to increasingly refined recommendations over time. So the more you use a platform
            the greater the knowledge the algorithm builds up about you. A larger sample results in better data and this
            can be applied to data about you. Eventually you will be only be exposed to content that you have shown past
            interest in, essentially defining your experience by past interests.
            <br /> <br />
            However, this can create a feedback loop where users are consistently exposed to content that reinforces
            their existing beliefs and interests. This can lead to the user being isolated in a "filter bubble" or "echo
            chamber", where they are only exposed to a narrow range of perspectives. This can result in someone becoming
            more pronounced in their beliefs regardless of their merit as they only see things that they like or agree
            with. This can be dangerous as it can make people more igonorant of the world around them.

        </p> <br />


        <h2>Conspiracy Theories & Algorithmic Amplification</h2>

        <p>Conspiracy theories often get a lot of engagement cause their wild. It is eye-catching which causes users to
            be more likely to click, like, share, and spend extended periods of time with conspiracy content.
            <br /> <br />
            Platforms, aiming to maximize user engagement, may prioritize and amplify the engagement of conspiracy
            theories. That is because the algorithms interpret high engagement as an indication that the content is good
            and of interest to a wide audience. This causes harmful information to be pushed out to a wider audience
            misinforming more people. This also results in a larger feedback loop where people start seeing more content
            with conspiracy theories which in turn creates more engagement with conspiracy theories

        </p> <br />

        <h2>Platform Incentives</h2>

        <p>
            The primary goal for many online platforms is to keep users engaged for as long as possible. This leads to
            increased ad impressions, which in turn boosts revenue. It also keeps users coming back to the platform
            which is important for the company to keep making profit.
            <br /> <br />
            However, this focus on engagement can sometimes lead to a neglect of content quality and truthfulness.
            Algorithms may promote sensational or false information over nuanced and factual content if it generates
            higher engagement. These algorithms simply looks at what gets the most engagement and often ignore the
            actual content. Some platforms like Instagram are now marking some items as false news if it is harmful, but
            it often does not catch harmful content and often marks real information as fake.

        </p> <br />
        <h2>Potential for Exploitation</h2>

        <p>
            Malicious actors can intentionally produce and promote content that feeds conspiracy theories. They may use
            crazy titles, misleading thumbnails, or divisive content to artificially boost engagement and manipulate the
            system to their advantage. This causes their content to achieve higher engagement without putting in much
            effort.
            <br /> <br />
            This exploitation can have significant consequences, as it can lead to the dissemination of false
            information and the reinforcement of divisive beliefs, ultimately affecting public discourse and potentially
            causing harm. The diffusion of false information can negatively affect
            <br /> <br />
            Overall, while recommendation algorithms serve the purpose of enhancing user experience, they can
            inadvertently contribute to the spread of conspiracy theories if not carefully managed. It's important for
            platforms to strike a balance between user engagement and content quality, and to implement checks to
            prevent malicious exploitation.


        </p> <br />

      
        <h2>Bibliography:</h2>
        <p class="hangingindent">GeeksforGeeks. (2023a, July 6). Merge sort - data structure and algorithms tutorials.
            GeeksforGeeks. https://www.geeksforgeeks.org/merge-sort/
        </p>
        <p class="hangingindent"> GeeksforGeeks. (2023b, July 25). Heap sort - data structures and algorithms tutorials.
            GeeksforGeeks. https://www.geeksforgeeks.org/heap-sort/
        </p>
        <p class="hangingindent"> OpenAI. (2023, August 28). Explanation of Sorting Algorithms and Their Performance.
            ChatGPT.
        </p>
    </div>
</body>

</html>